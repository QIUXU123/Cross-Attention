{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssrlab/.local/lib/python3.10/site-packages/lazy_loader/__init__.py:202: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/ssrlab/.local/lib/python3.10/site-packages/lazy_loader/__init__.py:202: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/ssrlab/anaconda3/envs/qx/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "# from vgg16 import VGG16_LSTM\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from facenet_pytorch import MTCNN\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from qx_noface_no2d_video_swin_transformer01 import SwinTransformer3D\n",
    "import gc\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def datasize(type,batchsz):\n",
    "    if type=='train':\n",
    "        i=5076#5967\n",
    "        while True:\n",
    "            if i%batchsz==0:\n",
    "                return i\n",
    "            else:\n",
    "                i-=1\n",
    "    else:\n",
    "        i=1701#1986\n",
    "        while True:\n",
    "            if i%batchsz==0:\n",
    "                return i\n",
    "            else:\n",
    "                i-=1\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def getdata(pathname,datatype):\n",
    "    if datatype==\"train\":\n",
    "        final_data_set=[]\n",
    "        output_file=open(pathname, \"rb\")\n",
    "        for i in range(1):\n",
    "            # train_data_set.extend(pickle.load(output_file))\n",
    "            final_data_set.extend(pickle.load(output_file))\n",
    "            # print(i)\n",
    "        return final_data_set\n",
    "    elif datatype==\"valid\":\n",
    "        final_data_set=[]\n",
    "        output_file=open(pathname, \"rb\")\n",
    "        for i in range(1):\n",
    "            valid_data_set=[]\n",
    "            final_data_set.extend(pickle.load(output_file))\n",
    "            del valid_data_set\n",
    "        return final_data_set\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def reshape_to_expected_validinput(dataset: List[Tuple[ np.ndarray, np.ndarray]]) -> Tuple[\n",
    "     np.ndarray, np.ndarray]:\n",
    "    result=[]\n",
    "    for i in range(0, len(dataset[0])):\n",
    "        result.append((dataset[0][i],dataset[1][i],dataset[2][i],dataset[3][i],dataset[4][i],dataset[5][i]))\n",
    "    result = result[:datasize(\"valid\",4)]\n",
    "    x0_list = []\n",
    "    x1_list = []\n",
    "    x2_list = []\n",
    "    x3_list = []\n",
    "    x4_list = []\n",
    "    x5_list = []\n",
    "    for i in range(0, len(result)):\n",
    "        x0_list.append(result[i][0])\n",
    "        x1_list.append(result[i][1])\n",
    "        x2_list.append(result[i][2])\n",
    "        x3_list.append(result[i][3])\n",
    "        x4_list.append(result[i][4])\n",
    "        x5_list.append(result[i][5])\n",
    "    return (np.stack(x0_list), np.stack(x1_list), np.stack(x2_list),np.stack(x3_list), np.stack(x4_list), np.stack(x5_list))\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def reshape_to_expected_traininput(dataset: List[Tuple[ np.ndarray, np.ndarray]]) -> Tuple[\n",
    "     np.ndarray, np.ndarray]:\n",
    "    result=[]\n",
    "    for i in range(0, len(dataset[0])):\n",
    "        result.append((dataset[0][i],dataset[1][i],dataset[2][i],dataset[3][i],dataset[4][i],dataset[5][i]))\n",
    "    result = result[:datasize(\"train\",4)]\n",
    "    x0_list = []\n",
    "    x1_list = []\n",
    "    x2_list = []\n",
    "    x3_list = []\n",
    "    x4_list = []\n",
    "    x5_list = []\n",
    "    for i in range(0, len(result)):\n",
    "        x0_list.append(result[i][0])\n",
    "        x1_list.append(result[i][1])\n",
    "        x2_list.append(result[i][2])\n",
    "        x3_list.append(result[i][3])\n",
    "        x4_list.append(result[i][4])\n",
    "        x5_list.append(result[i][5])\n",
    "    return (np.stack(x0_list), np.stack(x1_list), np.stack(x2_list),np.stack(x3_list), np.stack(x4_list), np.stack(x5_list))\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_data=getdata(\"/home/ssrlab/qx/code/test/video-swin-transformer-pytorch/data/15Frames/Full_frames/valid_set.dat\",\"train\")\n",
    "# train_set_data=reshape_to_expected_traininput(train_set_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1993"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
